{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from BayesNetReader import BayesNetReader\n",
    "from DataReader import CSV_DataReader\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPT_Generator(BayesNetReader):\n",
    "    configfile_name = None\n",
    "    bn = None\n",
    "    nbc = None\n",
    "    countings = {}\n",
    "    CPTs = {}\n",
    "    constant_l = 1  # to avoid zero probabilities\n",
    "\n",
    "    def __init__(self, configfile_name, datafile_name):\n",
    "        self.configfile_name = configfile_name\n",
    "        self.bn = BayesNetReader(configfile_name)\n",
    "        self.csv = CSV_DataReader(datafile_name)\n",
    "        self.generate_prior_and_conditional_countings()\n",
    "        self.generate_probabilities_from_countings()\n",
    "        self.write_CPTs_to_configuration_file()\n",
    "\n",
    "    def generate_prior_and_conditional_countings(self):\n",
    "        print(\"\\nGENERATING countings for prior/conditional distributions...\")\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "\n",
    "        for pd in self.bn.bn[\"structure\"]:\n",
    "            print(str(pd))\n",
    "            p = pd.replace('(', ' ')\n",
    "            p = p.replace(')', ' ')\n",
    "            tokens = p.split(\"|\")\n",
    "\n",
    "            # generate countings for prior probabilities\n",
    "            if len(tokens) == 1:\n",
    "                variable = tokens[0].split(' ')[1]\n",
    "                variable_index = self.get_variable_index(variable)\n",
    "                counts = self.initialise_counts(variable)\n",
    "                self.get_counts(variable_index, None, counts)\n",
    "\n",
    "            # generate countings for conditional probabilities\n",
    "            if len(tokens) == 2:\n",
    "                variable = tokens[0].split(' ')[1]\n",
    "                variable_index = self.get_variable_index(variable)\n",
    "                parents = tokens[1].strip().split(',')\n",
    "                parent_indexes = self.get_parent_indexes(parents)\n",
    "                counts = self.initialise_counts(variable, parents)\n",
    "                self.get_counts(variable_index, parent_indexes, counts)\n",
    "\n",
    "            self.countings[pd] = counts\n",
    "            print(\"counts=\"+str(counts))\n",
    "            print()\n",
    "\n",
    "    def generate_probabilities_from_countings(self):\n",
    "        print(\"\\nGENERATING prior and conditional probabilities...\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "        for pd, counts in self.countings.items():\n",
    "            print(str(pd))\n",
    "            tokens = pd.split(\"|\")\n",
    "            variable = tokens[0].replace(\"P(\", \"\")\n",
    "            cpt = {}\n",
    "\n",
    "            # generate prior probabilities\n",
    "            if len(tokens) == 1:\n",
    "                _sum = 0\n",
    "                for key, count in counts.items():\n",
    "                    _sum += count\n",
    "\n",
    "                Jl = len(counts)*self.constant_l\n",
    "                for key, count in counts.items():\n",
    "                    cpt[key] = (count+self.constant_l)/(_sum+Jl)\n",
    "\n",
    "            # generate conditional probabilities\n",
    "            if len(tokens) == 2:\n",
    "                parents_values = self.get_parent_values(counts)\n",
    "                for parents_value in parents_values:\n",
    "                    _sum = 0\n",
    "                    for key, count in counts.items():\n",
    "                        if key.endswith(\"|\"+parents_value):\n",
    "                            _sum += count\n",
    "\n",
    "                    J = len(self.csv.rv_key_values[variable])\n",
    "                    Jl = J*self.constant_l\n",
    "                    for key, count in counts.items():\n",
    "                        if key.endswith(\"|\"+parents_value):\n",
    "                            cpt[key] = (count+self.constant_l)/(_sum+Jl)\n",
    "\n",
    "            self.CPTs[pd] = cpt\n",
    "            print(\"CPT=\"+str(cpt))\n",
    "            print()\n",
    "\n",
    "    def get_variable_index(self, variable):\n",
    "        for i in range(0, len(self.csv.rand_vars)):\n",
    "            if variable == self.csv.rand_vars[i]:\n",
    "                return i\n",
    "        print(\"WARNING: couldn't find index of variables=%s\" % (variable))\n",
    "        return None\n",
    "\n",
    "    def get_parent_indexes(self, parents):\n",
    "        indexes = []\n",
    "        for parent in parents:\n",
    "            index = self.get_variable_index(parent)\n",
    "            indexes.append(index)\n",
    "        return indexes\n",
    "\n",
    "    def get_parent_values(self, counts):\n",
    "        values = []\n",
    "        for key, count in counts.items():\n",
    "            value = key.split('|')[1]\n",
    "            if value not in values:\n",
    "                values.append(value)\n",
    "        return values\n",
    "\n",
    "    def initialise_counts(self, variable, parents=None):\n",
    "        counts = {}\n",
    "\n",
    "        if parents is None:\n",
    "            # initialise counts of variables without parents\n",
    "            for var_val in self.csv.rv_key_values[variable]:\n",
    "                if var_val not in counts:\n",
    "                    counts[var_val] = 0\n",
    "\n",
    "        else:\n",
    "            # enumerate all sequence values of parent variables\n",
    "            parents_values = []\n",
    "            last_parents_values = []\n",
    "            for i in range(0, len(parents)):\n",
    "                parent = parents[i]\n",
    "                for var_val in self.csv.rv_key_values[parent]:\n",
    "                    if i == 0:\n",
    "                        parents_values.append(var_val)\n",
    "                    else:\n",
    "                        for last_val in last_parents_values:\n",
    "                            parents_values.append(last_val+','+var_val)\n",
    "\n",
    "                last_parents_values = parents_values.copy()\n",
    "                parents_values = []\n",
    "\n",
    "            # initialise counts of variables with parents\n",
    "            for var_val in self.csv.rv_key_values[variable]:\n",
    "                for par_val in last_parents_values:\n",
    "                    counts[var_val+'|'+par_val] = 0\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def get_counts(self, variable_index, parent_indexes, counts):\n",
    "        # accumulate countings\n",
    "        for values in self.csv.rv_all_values:\n",
    "            if parent_indexes is None:\n",
    "                # case: prior probability\n",
    "                value = values[variable_index]\n",
    "            else:\n",
    "                # case: conditional probability\n",
    "                parents_values = \"\"\n",
    "                for parent_index in parent_indexes:\n",
    "                    value = values[parent_index]\n",
    "                    if len(parents_values) == 0:\n",
    "                        parents_values = value\n",
    "                    else:\n",
    "                        parents_values += ','+value\n",
    "                value = values[variable_index]+'|'+parents_values\n",
    "            counts[value] += 1\n",
    "\n",
    "    def write_CPTs_to_configuration_file(self):\n",
    "        print(\"\\nWRITING config file with CPT tables...\")\n",
    "        print(\"See rewritten file \"+str(self.configfile_name))\n",
    "        print(\"---------------------------------------------------\")\n",
    "        name = self.bn.bn[\"name\"]\n",
    "\n",
    "        rand_vars = self.bn.bn[\"random_variables_raw\"]\n",
    "        rand_vars = str(rand_vars).replace('[', '').replace(']', '')\n",
    "        rand_vars = str(rand_vars).replace('\\'', '').replace(', ', ';')\n",
    "\n",
    "        structure = self.bn.bn[\"structure\"]\n",
    "        structure = str(structure).replace('[', '').replace(']', '')\n",
    "        structure = str(structure).replace('\\'', '').replace(', ', ';')\n",
    "\n",
    "        with open(self.configfile_name, 'w') as cfg_file:\n",
    "            cfg_file.write(\"name:\"+str(name))\n",
    "            cfg_file.write('\\n')\n",
    "            cfg_file.write('\\n')\n",
    "            cfg_file.write(\"random_variables:\"+str(rand_vars))\n",
    "            cfg_file.write('\\n')\n",
    "            cfg_file.write('\\n')\n",
    "            cfg_file.write(\"structure:\"+str(structure))\n",
    "            cfg_file.write('\\n')\n",
    "            cfg_file.write('\\n')\n",
    "            for key, cpt in self.CPTs.items():\n",
    "                cpt_header = key.replace(\"P(\", \"CPT(\")\n",
    "                cfg_file.write(str(cpt_header)+\":\")\n",
    "                cfg_file.write('\\n')\n",
    "                num_written_probs = 0\n",
    "                for domain_vals, probability in cpt.items():\n",
    "                    num_written_probs += 1\n",
    "                    line = str(domain_vals)+\"=\"+str(probability)\n",
    "                    line = line+\";\" if num_written_probs < len(cpt) else line\n",
    "                    cfg_file.write(line)\n",
    "                    cfg_file.write('\\n')\n",
    "                cfg_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"USAGE: CPT_Generator.py [your_config_file.txt] [training_file.csv]\")\n",
    "        print(\"EXAMPLE> CPT_Generator.py config-playtennis.txt play_tennis-train.csv\")\n",
    "        exit(0)\n",
    "    else:\n",
    "        configfile_name = sys.argv[1]\n",
    "        datafile_name = sys.argv[2]\n",
    "        CPT_Generator(configfile_name, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# CSV_DataReader.py\n",
    "#\n",
    "# This program is the data reading code of the Naive Bayes classifier from week 1.\n",
    "# It assumes the existance of data in CSV format, where the first line contains\n",
    "# the names of random variables -- the last being the variable to predict.\n",
    "#\n",
    "# Version: 1.0, Date: 20 September 2024\n",
    "# Contact: hcuayahuitl@lincoln.ac.uk\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "class CSV_DataReader:\n",
    "    rand_vars = []\n",
    "    rv_key_values = {}\n",
    "    rv_all_values = []\n",
    "    predictor_variable = None\n",
    "    num_data_instances = 0\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        if file_name is None:\n",
    "            return\n",
    "        else:\n",
    "            self.read_data(file_name)\n",
    "\n",
    "    def read_data(self, data_file):\n",
    "        print(\"\\nREADING data file %s...\" % (data_file))\n",
    "        print(\"---------------------------------------\")\n",
    "\n",
    "        self.rand_vars = []\n",
    "        self.rv_key_values = {}\n",
    "        self.rv_all_values = []\n",
    "\n",
    "        with open(data_file) as csv_file:\n",
    "            for line in csv_file:\n",
    "                line = line.strip()\n",
    "                if len(self.rand_vars) == 0:\n",
    "                    self.rand_vars = line.split(',')\n",
    "                    for variable in self.rand_vars:\n",
    "                        self.rv_key_values[variable] = []\n",
    "                else:\n",
    "                    values = line.split(',')\n",
    "                    self.rv_all_values.append(values)\n",
    "                    self.update_variable_key_values(values)\n",
    "                    self.num_data_instances += 1\n",
    "\n",
    "        self.predictor_variable = self.rand_vars[len(self.rand_vars)-1]\n",
    "\n",
    "        print(\"RANDOM VARIABLES=%s\" % (self.rand_vars))\n",
    "        print(\"VARIABLE KEY VALUES=%s\" % (self.rv_key_values))\n",
    "        print(\"VARIABLE VALUES=%s\" % (self.rv_all_values))\n",
    "        print(\"PREDICTOR VARIABLE=%s\" % (self.predictor_variable))\n",
    "        print(\"|data instances|=%d\" % (self.num_data_instances))\n",
    "\n",
    "    def update_variable_key_values(self, values):\n",
    "        for i in range(0, len(self.rand_vars)):\n",
    "            variable = self.rand_vars[i]\n",
    "            key_values = self.rv_key_values[variable]\n",
    "            value_in_focus = values[i]\n",
    "            if value_in_focus not in key_values:\n",
    "                self.rv_key_values[variable].append(value_in_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# BayesNetUtil.py\n",
    "#\n",
    "# Implements functions to simplify the implementation of algorithms for\n",
    "# probabilistic inference with Bayesian networks.\n",
    "#\n",
    "# Version: 1.0, 06 October 2022\n",
    "# Contact: hcuayahuitl@lincoln.ac.uk\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "def tokenise_query(prob_query):\n",
    "    print(\"\\nTOKENISING probabilistic query=\"+str(prob_query))\n",
    "\n",
    "    query = {}\n",
    "    prob_query = prob_query[2:]\n",
    "    prob_query = prob_query[:len(prob_query)-1]\n",
    "    query[\"query_var\"] = prob_query.split(\"|\")[0]\n",
    "    query[\"evidence\"] = prob_query.split(\"|\")[1]\n",
    "\n",
    "    evidence = {}\n",
    "    if query[\"evidence\"].find(','):\n",
    "        for pair in query[\"evidence\"].split(','):\n",
    "            tokens = pair.split('=')\n",
    "            evidence[tokens[0]] = tokens[1]\n",
    "        query[\"evidence\"] = evidence\n",
    "\n",
    "    print(\"query=\"+str(query))\n",
    "    return query\n",
    "\n",
    "\n",
    "def get_parents(child, bn):\n",
    "    for conditional in bn[\"structure\"]:\n",
    "        if conditional.startswith(\"P(\"+child+\")\"):\n",
    "            return None\n",
    "        elif conditional.startswith(\"P(\"+child+\"|\"):\n",
    "            parents = conditional.split(\"|\")[1]\n",
    "            parents = parents[:len(parents)-1]\n",
    "            return parents\n",
    "\n",
    "    print(\"ERROR: Couldn't find parent(s) of variable \"+str(child))\n",
    "    exit(0)\n",
    "\n",
    "\n",
    "def get_probability_given_parents(V, v, evidence, bn):\n",
    "    parents = get_parents(V, bn)\n",
    "    probability = 0\n",
    "    if parents is None:\n",
    "        cpt = bn[\"CPT(\"+V+\")\"]\n",
    "        probability = cpt[v]\n",
    "    else:\n",
    "        cpt = bn[\"CPT(\"+V+\"|\"+parents+\")\"]\n",
    "        values = v\n",
    "        for parent in parents.split(\",\"):\n",
    "            separator = \"|\" if values == v else \",\"\n",
    "            values = values + separator + evidence[parent]\n",
    "        probability = cpt[values]\n",
    "\n",
    "    return probability\n",
    "\n",
    "\n",
    "def get_domain_values(V, bn):\n",
    "    domain_values = []\n",
    "\n",
    "    for key, cpt in bn.items():\n",
    "        if key == \"CPT(\"+V+\")\":\n",
    "            domain_values = list(cpt.keys())\n",
    "\n",
    "        elif key.startswith(\"CPT(\"+V+\"|\"):\n",
    "            for entry, prob in cpt.items():\n",
    "                value = entry.split(\"|\")[0]\n",
    "                if value not in domain_values:\n",
    "                    domain_values.append(value)\n",
    "\n",
    "    if len(domain_values) == 0:\n",
    "        print(\"ERROR: Couldn't find values of variable \"+str(V))\n",
    "        exit(0)\n",
    "\n",
    "    return domain_values\n",
    "\n",
    "\n",
    "def get_index_of_variable(V, bn):\n",
    "    for i in range(0, len(bn[\"random_variables\"])):\n",
    "        variable = bn[\"random_variables\"][i]\n",
    "        if V == variable:\n",
    "            return i\n",
    "\n",
    "    print(\"ERROR: Couldn't find index of variable \"+str(V))\n",
    "    exit(0)\n",
    "\n",
    "\n",
    "def normalise(counts):\n",
    "    _sum = 0\n",
    "    for value, count in counts.items():\n",
    "        _sum += count\n",
    "\n",
    "    distribution = {}\n",
    "    for value, count in counts.items():\n",
    "        p = float(count/_sum)\n",
    "        distribution[value] = p\n",
    "\n",
    "    return distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV file into a DataFrame\n",
    "df1 = pd.read_csv(r'C:\\Users\\Student\\Documents\\Module Dev Containers\\AAI-assignment\\mycode\\dementia_data-MRI-features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV file into a DataFrame\n",
    "df1 = pd.read_csv(r'C:\\Users\\Student\\Documents\\Module Dev Containers\\AAI-assignment\\mycode\\dementia_data-MRI-features.csv')\n",
    "\n",
    "# Printing the shape of the DataFrame\n",
    "print(df1.shape)\n",
    "print(df1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using pandas `cut` function for equal-width bins, 4 bins in this case\n",
    "# bins=[59, 69, 79, 89, 99]\n",
    "# labels=[\"60-69\", \"70-79\", \"80-89\", \"90+\"]\n",
    "# df1['AgeGroup'] = pd.cut(df1['Age'], bins=bins, labels=labels)\n",
    "\n",
    "# df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values in column 'Group'\n",
    "df1['Group'].unique()\n",
    "\n",
    "# Filtering rows in df1 where the 'Group' column is equal to 'Converted' and assigning them to df2\n",
    "df2 = df1.loc[df1['Group'] == 'Converted']\n",
    "\n",
    "# Dropping the rows from df1 that have been assigned to df2 using the corresponding index values\n",
    "df1 = df1.drop(df2.index)\n",
    "\n",
    "#df1 is the data frame that doesn't have the converted data\n",
    "df1.head(40)\n",
    "\n",
    "#df2 is the new data frame that contains the converted data\n",
    "# df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'Last_Visit' to identify the last visit for each patient\n",
    "df2['Last_Visit'] = df2.groupby('Subject ID')['Visit'].transform('max')\n",
    "\n",
    "# Updating the 'Group' column based on 'Visit' and 'Last_Visit' conditions\n",
    "df2.loc[df2['Visit'] < df2['Last_Visit'], 'Group'] = 'Nondemented'\n",
    "df2.loc[df2['Visit'] == df2['Last_Visit'], 'Group'] = 'Demented'\n",
    "\n",
    "# Dropping the 'Last_Visit' column\n",
    "df2.drop('Last_Visit', axis=1, inplace=True)\n",
    "\n",
    "# Displaying the updated DataFrame\n",
    "df2.head(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the DataFrames df1 and df2\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df['Group'].unique()\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Domain-specific binning (if you have specific thresholds)\n",
    "# # Define custom bins based on clinical knowledge or research\n",
    "# # Example: Small, Medium, Large ranges (these ranges are illustrative)\n",
    "# bins = [1000, 1400, 1600, 2000]\n",
    "# labels = ['Small', 'Medium', 'Large']\n",
    "# df1['eTIV_custom'] = pd.cut(df1['eTIV'], bins=bins, labels=labels)\n",
    "\n",
    "# # Display the first few rows\n",
    "# df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the 'M/F' column to 'Gender' in the DataFrame\n",
    "df.rename(columns={'M/F': 'Gender'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns from the DataFrame if they exist\n",
    "columns_to_drop = ['Subject ID', 'MRI ID', 'Hand', 'Gender', 'MR Delay']\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "df.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the current column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the DataFrame\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values in the 'SES' column with the mode\n",
    "df.SES.fillna(df.SES.mode()[0], inplace=True)\n",
    "\n",
    "# Imputing missing values in the 'MMSE' column with the mean\n",
    "df.MMSE.fillna(df.MMSE.mean(), inplace=True)\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Creating a count plot with 'Group' on the x-axis\n",
    "sns.countplot(data=df, x='Group', palette='Set2').set(title = 'Dementia Group');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of 'Age' for each 'Group'\n",
    "sns.displot(data=df, x='Age', hue='Group', kind=\"kde\", palette='Set2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizing the correlation matrix of numeric columns using a heatmap\n",
    "sns.heatmap(df.corr(numeric_only=True), vmin=-1, cmap='coolwarm', annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the structure of the Bayesian Network\n",
    "model = bnlearn.structure_learning.fit(df)\n",
    "\n",
    "# Visualize the structure of the learned network\n",
    "# model.plot()\n",
    "bnlearn.plot(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
